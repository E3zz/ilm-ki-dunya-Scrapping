import scrapy

class WebspiderSpider(scrapy.Spider):
    name = "webspider"
    allowed_domains = ["www.studyabroad.pk"]
    start_urls = ["https://www.studyabroad.pk/scholarships"]

    def parse(self, response):
        scholarships = response.css(".list-container")
        for scholarship in scholarships:
            relative_urls = scholarship.xpath(".//div[@class='uni-imagez']/following-sibling::div/a/@href").getall()
            for relative_url in relative_urls:
                absolute_url = response.urljoin(relative_url)
                yield scrapy.Request(absolute_url, callback=self.parse_scholarship)

    def parse_scholarship(self, response):
        level =  response.xpath("//div[@class='sch_title']//span[@class='otherp'][1]/text()").get(default='').strip()
        course = response.xpath("//div[@class='sch_title']//span[@class='otherp'][2]/text()").get(default='').strip()
        scholarship_name =  response.xpath('//div[@class="sch_title"]/text()').get(default='').strip()
        scholarship_text = scholarship_name.replace('\xa0',' ')
        deadline = response.css('div.sch_country strong::text').get()
        university = response.xpath('normalize-space(//p[strong="University or Organization:"]/text())').get()
        university_text = university.replace('\xa0',' ')
        country = response.css('div.sch_country small:nth-child(2)::text').get()

        yield {
        'level': level,
        'course': course,
        'scholarship_name': scholarship_name,
        'scholarship_text': scholarship_text,
        'deadline': deadline,
        'university': university_text,
        'country': country
}